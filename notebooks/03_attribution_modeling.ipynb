{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üéØ Multi-Touch Attribution Modeling\n",
                "\n",
                "## Social Media ROI Attribution & Influencer Performance Analyzer\n",
                "\n",
                "This notebook builds attribution models to understand which touchpoints drive conversions:\n",
                "- First-Touch Attribution\n",
                "- Last-Touch Attribution\n",
                "- Linear Attribution\n",
                "- Time-Decay Attribution\n",
                "- Position-Based Attribution\n",
                "- Markov Chain (Data-Driven) Attribution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "from collections import defaultdict\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (12, 6)\n",
                "\n",
                "print(\"‚úÖ Libraries loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load data\n",
                "data_dir = Path(\"../data/raw\")\n",
                "\n",
                "conversions = pd.read_csv(data_dir / \"conversions.csv\")\n",
                "touchpoints = pd.read_csv(data_dir / \"touchpoints.csv\")\n",
                "posts = pd.read_csv(data_dir / \"posts.csv\")\n",
                "influencers = pd.read_csv(data_dir / \"influencers.csv\")\n",
                "\n",
                "# Parse dates\n",
                "conversions['conversion_date'] = pd.to_datetime(conversions['conversion_date'])\n",
                "touchpoints['touchpoint_date'] = pd.to_datetime(touchpoints['touchpoint_date'])\n",
                "\n",
                "print(f\"üìä Loaded {len(conversions):,} conversions and {len(touchpoints):,} touchpoints\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Data Preparation - Build Customer Journeys"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get touchpoints that led to conversions\n",
                "converting_touchpoints = touchpoints[touchpoints['contributed_to_conversion'] == True].copy()\n",
                "\n",
                "# Join with conversion data\n",
                "journeys = converting_touchpoints.merge(\n",
                "    conversions[['conversion_id', 'customer_id', 'order_value', 'conversion_date']], \n",
                "    on='conversion_id',\n",
                "    suffixes=('', '_conv')\n",
                ")\n",
                "\n",
                "# Sort by customer and date\n",
                "journeys = journeys.sort_values(['customer_id_conv', 'touchpoint_date'])\n",
                "\n",
                "print(f\"üìç {len(journeys):,} touchpoints in converting journeys\")\n",
                "print(f\"üë• {journeys['conversion_id'].nunique():,} unique conversions with touchpoints\")\n",
                "\n",
                "journeys.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Build journey paths\n",
                "def build_journey_paths(df):\n",
                "    \"\"\"Build journey paths for each conversion.\"\"\"\n",
                "    paths = []\n",
                "    \n",
                "    for conv_id, group in df.groupby('conversion_id'):\n",
                "        group = group.sort_values('touchpoint_date')\n",
                "        path = list(group['platform'].values)\n",
                "        touchpoint_types = list(group['touchpoint_type'].values)\n",
                "        order_value = group['order_value'].iloc[0]\n",
                "        \n",
                "        paths.append({\n",
                "            'conversion_id': conv_id,\n",
                "            'path': path,\n",
                "            'touchpoint_types': touchpoint_types,\n",
                "            'path_length': len(path),\n",
                "            'order_value': order_value\n",
                "        })\n",
                "    \n",
                "    return pd.DataFrame(paths)\n",
                "\n",
                "journey_paths = build_journey_paths(journeys)\n",
                "print(f\"üìä Built {len(journey_paths):,} journey paths\")\n",
                "print(f\"\\nüìç Average path length: {journey_paths['path_length'].mean():.2f} touchpoints\")\n",
                "\n",
                "journey_paths.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Attribution Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def first_touch_attribution(paths_df):\n",
                "    \"\"\"Assign 100% credit to first touchpoint.\"\"\"\n",
                "    attribution = defaultdict(float)\n",
                "    \n",
                "    for _, row in paths_df.iterrows():\n",
                "        if len(row['path']) > 0:\n",
                "            first_channel = row['path'][0]\n",
                "            attribution[first_channel] += row['order_value']\n",
                "    \n",
                "    return dict(attribution)\n",
                "\n",
                "def last_touch_attribution(paths_df):\n",
                "    \"\"\"Assign 100% credit to last touchpoint.\"\"\"\n",
                "    attribution = defaultdict(float)\n",
                "    \n",
                "    for _, row in paths_df.iterrows():\n",
                "        if len(row['path']) > 0:\n",
                "            last_channel = row['path'][-1]\n",
                "            attribution[last_channel] += row['order_value']\n",
                "    \n",
                "    return dict(attribution)\n",
                "\n",
                "def linear_attribution(paths_df):\n",
                "    \"\"\"Assign equal credit to all touchpoints.\"\"\"\n",
                "    attribution = defaultdict(float)\n",
                "    \n",
                "    for _, row in paths_df.iterrows():\n",
                "        path = row['path']\n",
                "        if len(path) > 0:\n",
                "            credit_per_channel = row['order_value'] / len(path)\n",
                "            for channel in path:\n",
                "                attribution[channel] += credit_per_channel\n",
                "    \n",
                "    return dict(attribution)\n",
                "\n",
                "def time_decay_attribution(paths_df, decay_rate=0.5):\n",
                "    \"\"\"More credit to recent touchpoints.\"\"\"\n",
                "    attribution = defaultdict(float)\n",
                "    \n",
                "    for _, row in paths_df.iterrows():\n",
                "        path = row['path']\n",
                "        if len(path) > 0:\n",
                "            # Calculate weights (more recent = higher weight)\n",
                "            weights = [decay_rate ** (len(path) - 1 - i) for i in range(len(path))]\n",
                "            total_weight = sum(weights)\n",
                "            \n",
                "            for i, channel in enumerate(path):\n",
                "                credit = row['order_value'] * (weights[i] / total_weight)\n",
                "                attribution[channel] += credit\n",
                "    \n",
                "    return dict(attribution)\n",
                "\n",
                "def position_based_attribution(paths_df):\n",
                "    \"\"\"40% first, 40% last, 20% middle.\"\"\"\n",
                "    attribution = defaultdict(float)\n",
                "    \n",
                "    for _, row in paths_df.iterrows():\n",
                "        path = row['path']\n",
                "        if len(path) == 0:\n",
                "            continue\n",
                "        elif len(path) == 1:\n",
                "            attribution[path[0]] += row['order_value']\n",
                "        elif len(path) == 2:\n",
                "            attribution[path[0]] += row['order_value'] * 0.5\n",
                "            attribution[path[1]] += row['order_value'] * 0.5\n",
                "        else:\n",
                "            # First touch: 40%\n",
                "            attribution[path[0]] += row['order_value'] * 0.4\n",
                "            # Last touch: 40%\n",
                "            attribution[path[-1]] += row['order_value'] * 0.4\n",
                "            # Middle: 20% split\n",
                "            middle = path[1:-1]\n",
                "            if len(middle) > 0:\n",
                "                middle_credit = row['order_value'] * 0.2 / len(middle)\n",
                "                for channel in middle:\n",
                "                    attribution[channel] += middle_credit\n",
                "    \n",
                "    return dict(attribution)\n",
                "\n",
                "print(\"‚úÖ Attribution functions defined!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate all attributions\n",
                "first_touch = first_touch_attribution(journey_paths)\n",
                "last_touch = last_touch_attribution(journey_paths)\n",
                "linear = linear_attribution(journey_paths)\n",
                "time_decay = time_decay_attribution(journey_paths)\n",
                "position_based = position_based_attribution(journey_paths)\n",
                "\n",
                "# Combine into DataFrame\n",
                "all_channels = set(first_touch.keys()) | set(last_touch.keys()) | set(linear.keys())\n",
                "\n",
                "attribution_df = pd.DataFrame({\n",
                "    'Channel': list(all_channels),\n",
                "    'First Touch': [first_touch.get(c, 0) for c in all_channels],\n",
                "    'Last Touch': [last_touch.get(c, 0) for c in all_channels],\n",
                "    'Linear': [linear.get(c, 0) for c in all_channels],\n",
                "    'Time Decay': [time_decay.get(c, 0) for c in all_channels],\n",
                "    'Position Based': [position_based.get(c, 0) for c in all_channels]\n",
                "}).set_index('Channel').round(2)\n",
                "\n",
                "attribution_df = attribution_df.sort_values('Linear', ascending=False)\n",
                "\n",
                "print(\"üìä Attribution by Channel (Revenue $)\")\n",
                "print(attribution_df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize attribution comparison\n",
                "fig, ax = plt.subplots(figsize=(14, 8))\n",
                "\n",
                "x = np.arange(len(attribution_df.index))\n",
                "width = 0.15\n",
                "\n",
                "models = ['First Touch', 'Last Touch', 'Linear', 'Time Decay', 'Position Based']\n",
                "colors = sns.color_palette('husl', len(models))\n",
                "\n",
                "for i, model in enumerate(models):\n",
                "    ax.bar(x + i * width, attribution_df[model], width, label=model, color=colors[i])\n",
                "\n",
                "ax.set_ylabel('Attributed Revenue ($)', fontsize=12)\n",
                "ax.set_title('Channel Attribution Comparison Across Models', fontweight='bold', fontsize=16)\n",
                "ax.set_xticks(x + width * 2)\n",
                "ax.set_xticklabels(attribution_df.index, rotation=45, ha='right')\n",
                "ax.legend(title='Attribution Model')\n",
                "ax.grid(axis='y', alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/attribution_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Markov Chain Attribution (Data-Driven)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def build_transition_matrix(paths_df):\n",
                "    \"\"\"Build Markov transition probability matrix.\"\"\"\n",
                "    transitions = defaultdict(lambda: defaultdict(int))\n",
                "    \n",
                "    for _, row in paths_df.iterrows():\n",
                "        path = ['Start'] + row['path'] + ['Conversion']\n",
                "        for i in range(len(path) - 1):\n",
                "            transitions[path[i]][path[i+1]] += 1\n",
                "    \n",
                "    # Convert to probabilities\n",
                "    transition_probs = {}\n",
                "    for from_state, to_states in transitions.items():\n",
                "        total = sum(to_states.values())\n",
                "        transition_probs[from_state] = {to_state: count/total for to_state, count in to_states.items()}\n",
                "    \n",
                "    return transition_probs\n",
                "\n",
                "def calculate_removal_effect(paths_df, channel_to_remove):\n",
                "    \"\"\"Calculate conversion probability with a channel removed.\"\"\"\n",
                "    # Filter out journeys containing the channel\n",
                "    remaining = paths_df[~paths_df['path'].apply(lambda x: channel_to_remove in x)]\n",
                "    return len(remaining) / len(paths_df) if len(paths_df) > 0 else 0\n",
                "\n",
                "def markov_attribution(paths_df):\n",
                "    \"\"\"Calculate Markov chain attribution using removal effect.\"\"\"\n",
                "    # Get all unique channels\n",
                "    all_channels = set()\n",
                "    for path in paths_df['path']:\n",
                "        all_channels.update(path)\n",
                "    \n",
                "    # Base conversion rate\n",
                "    base_conversions = len(paths_df)\n",
                "    \n",
                "    # Calculate removal effect for each channel\n",
                "    removal_effects = {}\n",
                "    for channel in all_channels:\n",
                "        paths_without_channel = paths_df[~paths_df['path'].apply(lambda x: channel in x)]\n",
                "        remaining_conv = len(paths_without_channel)\n",
                "        removal_effects[channel] = 1 - (remaining_conv / base_conversions) if base_conversions > 0 else 0\n",
                "    \n",
                "    # Normalize to sum to 1\n",
                "    total_effect = sum(removal_effects.values())\n",
                "    if total_effect > 0:\n",
                "        normalized = {k: v/total_effect for k, v in removal_effects.items()}\n",
                "    else:\n",
                "        normalized = removal_effects\n",
                "    \n",
                "    # Apply to total revenue\n",
                "    total_revenue = paths_df['order_value'].sum()\n",
                "    markov_attribution = {k: v * total_revenue for k, v in normalized.items()}\n",
                "    \n",
                "    return markov_attribution\n",
                "\n",
                "# Calculate Markov attribution\n",
                "markov = markov_attribution(journey_paths)\n",
                "attribution_df['Markov (Data-Driven)'] = pd.Series(markov)\n",
                "attribution_df = attribution_df.fillna(0).round(2)\n",
                "\n",
                "print(\"üìä Attribution by Channel (Including Markov)\")\n",
                "print(attribution_df)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Attribution Insights"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate percentage shares\n",
                "attribution_pct = attribution_df.div(attribution_df.sum()) * 100\n",
                "\n",
                "print(\"üìä Attribution Share (%) by Model\")\n",
                "print(attribution_pct.round(1))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize difference between models\n",
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "\n",
                "models = ['First Touch', 'Last Touch', 'Linear', 'Time Decay', 'Position Based', 'Markov (Data-Driven)']\n",
                "colors = sns.color_palette('Set2', len(attribution_df))\n",
                "\n",
                "for i, model in enumerate(models):\n",
                "    ax = axes[i//3, i%3]\n",
                "    data = attribution_pct[model].sort_values(ascending=False)\n",
                "    ax.pie(data.values, labels=data.index, autopct='%1.1f%%', colors=colors)\n",
                "    ax.set_title(model, fontweight='bold', fontsize=12)\n",
                "\n",
                "plt.suptitle('Channel Attribution by Model', fontweight='bold', fontsize=16, y=1.02)\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/attribution_pies.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Key insights\n",
                "print(\"=\"*60)\n",
                "print(\"üéØ ATTRIBUTION INSIGHTS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "for model in ['First Touch', 'Last Touch', 'Linear', 'Markov (Data-Driven)']:\n",
                "    top_channel = attribution_pct[model].idxmax()\n",
                "    top_pct = attribution_pct[model].max()\n",
                "    print(f\"\\n{model}: {top_channel} ({top_pct:.1f}%)\")\n",
                "\n",
                "# Identify undervalued/overvalued channels\n",
                "print(\"\\nüìà Channel Valuation Differences:\")\n",
                "for channel in attribution_df.index:\n",
                "    first = attribution_pct.loc[channel, 'First Touch']\n",
                "    last = attribution_pct.loc[channel, 'Last Touch']\n",
                "    diff = last - first\n",
                "    if abs(diff) > 5:\n",
                "        direction = \"Closer\" if diff > 0 else \"Introducer\"\n",
                "        print(f\"   {channel}: {direction} ({diff:+.1f}% shift from first to last touch)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Touchpoint Type Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Analyze touchpoint types in the journey\n",
                "touchpoint_type_analysis = journeys.groupby('touchpoint_type').agg({\n",
                "    'touchpoint_id': 'count',\n",
                "    'order_value': 'sum'\n",
                "}).rename(columns={'touchpoint_id': 'count'})\n",
                "\n",
                "touchpoint_type_analysis['avg_value'] = touchpoint_type_analysis['order_value'] / touchpoint_type_analysis['count']\n",
                "touchpoint_type_analysis = touchpoint_type_analysis.sort_values('order_value', ascending=False)\n",
                "\n",
                "print(\"üìç Touchpoint Type Analysis\")\n",
                "print(touchpoint_type_analysis.round(2))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Touchpoint frequency\n",
                "touchpoint_type_analysis['count'].plot(kind='bar', ax=axes[0], color=sns.color_palette('viridis', len(touchpoint_type_analysis)))\n",
                "axes[0].set_title('Touchpoint Type Frequency in Converting Journeys', fontweight='bold', fontsize=12)\n",
                "axes[0].set_ylabel('Count')\n",
                "axes[0].tick_params(axis='x', rotation=45)\n",
                "\n",
                "# Revenue by touchpoint type\n",
                "touchpoint_type_analysis['order_value'].plot(kind='bar', ax=axes[1], color=sns.color_palette('viridis', len(touchpoint_type_analysis)))\n",
                "axes[1].set_title('Revenue by Touchpoint Type', fontweight='bold', fontsize=12)\n",
                "axes[1].set_ylabel('Revenue ($)')\n",
                "axes[1].tick_params(axis='x', rotation=45)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../data/touchpoint_analysis.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## ‚úÖ Attribution Modeling Complete!\n",
                "\n",
                "**Key Outputs:**\n",
                "- Channel attribution across 6 models\n",
                "- Touchpoint type analysis\n",
                "- Journey path insights\n",
                "\n",
                "**Charts saved:**\n",
                "- `attribution_comparison.png`\n",
                "- `attribution_pies.png`\n",
                "- `touchpoint_analysis.png`\n",
                "\n",
                "**Next: Run `04_influencer_scoring.ipynb` to build influencer effectiveness model**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}