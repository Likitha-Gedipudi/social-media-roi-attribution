{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üìä Social Media ROI Attribution - Data Generation\n",
                "\n",
                "This notebook generates synthetic, unbiased data for the Social Media ROI Attribution & Influencer Performance Analyzer project.\n",
                "\n",
                "**Datasets Generated:**\n",
                "- 1,500 Influencers\n",
                "- 50,000 Posts\n",
                "- 25 Brands\n",
                "- 30,000 Conversions\n",
                "- 100,000 Touchpoints"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install pandas numpy scipy faker matplotlib seaborn -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from datetime import datetime, timedelta\n",
                "from uuid import uuid4\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "np.random.seed(42)\n",
                "\n",
                "# Set style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('husl')\n",
                "\n",
                "print(\"‚úÖ Libraries loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration & Industry Benchmarks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================\n",
                "# CONFIGURATION - Industry Benchmarks\n",
                "# Sources: Sprout Social, Later, HubSpot, Influencer Marketing Hub\n",
                "# ============================================\n",
                "\n",
                "# Dataset sizes\n",
                "N_INFLUENCERS = 1500\n",
                "N_POSTS = 50000\n",
                "N_BRANDS = 25\n",
                "N_CONVERSIONS = 30000\n",
                "N_TOUCHPOINTS = 100000\n",
                "\n",
                "# Date range\n",
                "DATE_START = \"2024-02-01\"\n",
                "DATE_END = \"2025-01-31\"\n",
                "\n",
                "# Platform distribution (fashion industry)\n",
                "PLATFORM_DIST = {\"Instagram\": 0.45, \"TikTok\": 0.35, \"YouTube\": 0.12, \"Twitter\": 0.08}\n",
                "\n",
                "# Influencer tier distribution (industry standard)\n",
                "TIER_DIST = {\"nano\": 0.40, \"micro\": 0.35, \"mid\": 0.15, \"macro\": 0.07, \"mega\": 0.03}\n",
                "\n",
                "# Follower ranges by tier\n",
                "TIER_FOLLOWERS = {\n",
                "    \"nano\": (1000, 10000), \"micro\": (10000, 100000), \n",
                "    \"mid\": (100000, 500000), \"macro\": (500000, 1000000), \"mega\": (1000000, 10000000)\n",
                "}\n",
                "\n",
                "# Engagement rates by tier (mean, std) - inversely correlated with followers\n",
                "TIER_ENGAGEMENT = {\n",
                "    \"nano\": (6.0, 1.5), \"micro\": (3.5, 1.0), \n",
                "    \"mid\": (2.2, 0.6), \"macro\": (1.5, 0.4), \"mega\": (1.0, 0.3)\n",
                "}\n",
                "\n",
                "# Audience authenticity by tier\n",
                "TIER_AUTHENTICITY = {\n",
                "    \"nano\": (0.92, 0.05), \"micro\": (0.88, 0.06), \n",
                "    \"mid\": (0.82, 0.08), \"macro\": (0.75, 0.10), \"mega\": (0.70, 0.12)\n",
                "}\n",
                "\n",
                "# Cost per post by tier (USD)\n",
                "TIER_COST = {\n",
                "    \"nano\": (50, 150), \"micro\": (150, 1000), \n",
                "    \"mid\": (1000, 5000), \"macro\": (5000, 15000), \"mega\": (15000, 100000)\n",
                "}\n",
                "\n",
                "# Gender distribution (balanced)\n",
                "GENDER_DIST = {\"Female\": 0.48, \"Male\": 0.45, \"Non-binary\": 0.05, \"Unknown\": 0.02}\n",
                "\n",
                "# Geographic distribution (avoid US-centric bias)\n",
                "COUNTRY_DIST = {\n",
                "    \"United States\": 0.30, \"United Kingdom\": 0.12, \"Germany\": 0.08, \"France\": 0.07,\n",
                "    \"Italy\": 0.05, \"Spain\": 0.05, \"Australia\": 0.05, \"Canada\": 0.05,\n",
                "    \"Japan\": 0.04, \"South Korea\": 0.04, \"Brazil\": 0.04, \"India\": 0.04,\n",
                "    \"Mexico\": 0.03, \"Netherlands\": 0.02, \"Sweden\": 0.02\n",
                "}\n",
                "\n",
                "# Age groups\n",
                "AGE_DIST = {\"18-24\": 0.35, \"25-34\": 0.40, \"35-44\": 0.18, \"45+\": 0.07}\n",
                "\n",
                "# Content categories\n",
                "CONTENT_CATEGORIES = [\"Luxury Fashion\", \"Streetwear\", \"Sustainable Fashion\", \"Fast Fashion\", \n",
                "                      \"Accessories\", \"Footwear\", \"Activewear\", \"Vintage/Thrift\"]\n",
                "\n",
                "# Visual styles\n",
                "VISUAL_STYLES = {\"lifestyle\": 0.35, \"product_shot\": 0.30, \"behind_scenes\": 0.15, \n",
                "                 \"user_generated\": 0.12, \"editorial\": 0.08}\n",
                "\n",
                "# Brand tiers  \n",
                "BRAND_TIERS = {\"Luxury\": 0.20, \"Premium\": 0.25, \"Mid-market\": 0.30, \"Fast-fashion\": 0.15, \"DTC\": 0.10}\n",
                "\n",
                "# Average order value by brand tier\n",
                "BRAND_AOV = {\n",
                "    \"Luxury\": (500, 2000), \"Premium\": (150, 500), \"Mid-market\": (50, 150),\n",
                "    \"Fast-fashion\": (25, 75), \"DTC\": (75, 200)\n",
                "}\n",
                "\n",
                "# Seasonality (fashion: Q4 peak, summer dip)\n",
                "SEASONALITY = {\n",
                "    1: 0.85, 2: 0.90, 3: 0.95, 4: 1.00, 5: 0.95, 6: 0.85,\n",
                "    7: 0.80, 8: 0.90, 9: 1.05, 10: 1.10, 11: 1.20, 12: 1.25\n",
                "}\n",
                "\n",
                "# Dominant colors\n",
                "COLORS = [\"neutral_beige\", \"cream_white\", \"classic_black\", \"navy_blue\", \"olive_green\",\n",
                "          \"terracotta\", \"dusty_rose\", \"burgundy\", \"camel_brown\", \"sage_green\"]\n",
                "\n",
                "print(\"‚úÖ Configuration loaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sample_dist(dist, n=1):\n",
                "    \"\"\"Sample from a categorical distribution.\"\"\"\n",
                "    return np.random.choice(list(dist.keys()), size=n, p=list(dist.values()))\n",
                "\n",
                "def gen_followers(tier):\n",
                "    \"\"\"Generate follower count (log-normal within tier).\"\"\"\n",
                "    low, high = TIER_FOLLOWERS[tier]\n",
                "    log_low, log_high = np.log(low), np.log(high)\n",
                "    return int(np.exp(np.random.uniform(log_low, log_high)))\n",
                "\n",
                "def gen_engagement(tier):\n",
                "    \"\"\"Generate engagement rate based on tier.\"\"\"\n",
                "    mean, std = TIER_ENGAGEMENT[tier]\n",
                "    return np.clip(np.random.normal(mean, std), 0.5, 12.0)\n",
                "\n",
                "def gen_authenticity(tier):\n",
                "    \"\"\"Generate authenticity score based on tier.\"\"\"\n",
                "    mean, std = TIER_AUTHENTICITY[tier]\n",
                "    return np.clip(np.random.normal(mean, std), 0.4, 0.99)\n",
                "\n",
                "def gen_cost(tier, followers):\n",
                "    \"\"\"Generate cost per post.\"\"\"\n",
                "    low, high = TIER_COST[tier]\n",
                "    tier_range = TIER_FOLLOWERS[tier]\n",
                "    position = (followers - tier_range[0]) / (tier_range[1] - tier_range[0])\n",
                "    base_cost = low + position * (high - low)\n",
                "    return round(base_cost * np.random.uniform(0.8, 1.2), 2)\n",
                "\n",
                "def gen_engagement_metrics(followers, eng_rate, is_viral=False):\n",
                "    \"\"\"Generate likes, comments, shares, saves.\"\"\"\n",
                "    variance = np.random.uniform(0.7, 1.3)\n",
                "    if is_viral:\n",
                "        variance *= np.random.uniform(3, 10)\n",
                "    \n",
                "    total = int(followers * (eng_rate / 100) * variance)\n",
                "    likes = int(total * np.random.uniform(0.85, 0.92))\n",
                "    comments = int(likes * np.random.uniform(0.03, 0.08))\n",
                "    shares = int(likes * np.random.uniform(0.01, 0.025))\n",
                "    saves = int(likes * np.random.uniform(0.02, 0.05))\n",
                "    \n",
                "    return max(1, likes), max(0, comments), max(0, shares), max(0, saves)\n",
                "\n",
                "def gen_order_value(brand_tier):\n",
                "    \"\"\"Generate order value (log-normal).\"\"\"\n",
                "    low, high = BRAND_AOV[brand_tier]\n",
                "    log_low, log_high = np.log(low), np.log(high)\n",
                "    value = np.exp(np.random.normal((log_low + log_high) / 2, (log_high - log_low) / 4))\n",
                "    return round(np.clip(value, low * 0.5, high * 1.5), 2)\n",
                "\n",
                "print(\"‚úÖ Helper functions defined!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Generate Datasets"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 Generate Brands"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üè¢ Generating Brands...\")\n",
                "\n",
                "brand_prefixes = [\"Maison\", \"Atelier\", \"Casa\", \"Studio\", \"House of\", \"La\", \"Le\", \"The\", \"Modern\", \"Luxe\"]\n",
                "brand_suffixes = [\"Mode\", \"Style\", \"Vogue\", \"Chic\", \"Edit\", \"Label\", \"Collective\", \"Co\", \"Design\", \"Wear\"]\n",
                "\n",
                "brands = []\n",
                "tiers = sample_dist(BRAND_TIERS, N_BRANDS)\n",
                "\n",
                "for i in range(N_BRANDS):\n",
                "    tier = tiers[i]\n",
                "    budget_ranges = {\n",
                "        \"Luxury\": (200000, 500000), \"Premium\": (100000, 250000), \n",
                "        \"Mid-market\": (50000, 150000), \"Fast-fashion\": (75000, 200000), \"DTC\": (25000, 100000)\n",
                "    }\n",
                "    low, high = budget_ranges[tier]\n",
                "    \n",
                "    brands.append({\n",
                "        \"brand_id\": str(uuid4()),\n",
                "        \"brand_name\": f\"{np.random.choice(brand_prefixes)} {np.random.choice(brand_suffixes)}\",\n",
                "        \"brand_tier\": tier,\n",
                "        \"monthly_social_budget\": round(np.random.uniform(low, high), 2),\n",
                "        \"primary_platform\": sample_dist(PLATFORM_DIST)[0],\n",
                "        \"avg_product_price\": gen_order_value(tier),\n",
                "        \"target_demographic\": np.random.choice([\"18-24\", \"25-34\", \"35-44\", \"25-44\"]),\n",
                "        \"founded_year\": np.random.randint(1990, 2022)\n",
                "    })\n",
                "\n",
                "brands_df = pd.DataFrame(brands)\n",
                "print(f\"‚úÖ Generated {len(brands_df)} brands\")\n",
                "brands_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.2 Generate Influencers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üë§ Generating Influencers...\")\n",
                "\n",
                "influencers = []\n",
                "tiers = sample_dist(TIER_DIST, N_INFLUENCERS)\n",
                "platforms = sample_dist(PLATFORM_DIST, N_INFLUENCERS)\n",
                "countries = sample_dist(COUNTRY_DIST, N_INFLUENCERS)\n",
                "genders = sample_dist(GENDER_DIST, N_INFLUENCERS)\n",
                "ages = sample_dist(AGE_DIST, N_INFLUENCERS)\n",
                "\n",
                "for i in range(N_INFLUENCERS):\n",
                "    tier = tiers[i]\n",
                "    followers = gen_followers(tier)\n",
                "    \n",
                "    influencers.append({\n",
                "        \"influencer_id\": str(uuid4()),\n",
                "        \"username\": f\"creator_{i+1:05d}\",\n",
                "        \"platform\": platforms[i],\n",
                "        \"tier\": tier,\n",
                "        \"follower_count\": followers,\n",
                "        \"engagement_rate\": round(gen_engagement(tier), 2),\n",
                "        \"country\": countries[i],\n",
                "        \"content_category\": np.random.choice(CONTENT_CATEGORIES),\n",
                "        \"avg_post_frequency\": round(np.clip(np.random.normal(4.2, 1.5), 1, 10), 1),\n",
                "        \"audience_authenticity_score\": round(gen_authenticity(tier), 2),\n",
                "        \"avg_collaboration_cost\": gen_cost(tier, followers),\n",
                "        \"account_age_months\": np.random.randint(12, 96),\n",
                "        \"gender\": genders[i],\n",
                "        \"age_group\": ages[i],\n",
                "        \"verified\": np.random.random() < (0.1 if tier in [\"nano\", \"micro\"] else 0.5),\n",
                "        \"active\": np.random.random() < 0.95\n",
                "    })\n",
                "\n",
                "influencers_df = pd.DataFrame(influencers)\n",
                "print(f\"‚úÖ Generated {len(influencers_df)} influencers\")\n",
                "influencers_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.3 Generate Posts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üì± Generating Posts...\")\n",
                "\n",
                "# Date range\n",
                "start_date = datetime.strptime(DATE_START, \"%Y-%m-%d\")\n",
                "end_date = datetime.strptime(DATE_END, \"%Y-%m-%d\")\n",
                "date_range = (end_date - start_date).days\n",
                "\n",
                "# Lookups\n",
                "inf_ids = influencers_df[\"influencer_id\"].tolist()\n",
                "brand_ids = brands_df[\"brand_id\"].tolist()\n",
                "inf_lookup = influencers_df.set_index(\"influencer_id\").to_dict(\"index\")\n",
                "\n",
                "# Content types by platform\n",
                "CONTENT_TYPES = {\n",
                "    \"Instagram\": {\"photo\": 0.35, \"carousel\": 0.25, \"reel\": 0.30, \"story\": 0.10},\n",
                "    \"TikTok\": {\"video\": 0.95, \"photo\": 0.05},\n",
                "    \"YouTube\": {\"video\": 0.85, \"shorts\": 0.15},\n",
                "    \"Twitter\": {\"photo\": 0.50, \"video\": 0.25, \"text\": 0.25}\n",
                "}\n",
                "\n",
                "posts = []\n",
                "for i in range(N_POSTS):\n",
                "    inf_id = np.random.choice(inf_ids)\n",
                "    inf = inf_lookup[inf_id]\n",
                "    platform = inf[\"platform\"]\n",
                "    \n",
                "    # Date with seasonality\n",
                "    random_days = np.random.randint(0, date_range)\n",
                "    post_date = start_date + timedelta(days=random_days)\n",
                "    month = post_date.month\n",
                "    \n",
                "    # Content type\n",
                "    content_types = CONTENT_TYPES.get(platform, {\"photo\": 1.0})\n",
                "    content_type = sample_dist(content_types)[0]\n",
                "    \n",
                "    # Sponsored?\n",
                "    is_sponsored = np.random.random() < (0.25 if inf[\"tier\"] in [\"mid\", \"macro\", \"mega\"] else 0.10)\n",
                "    \n",
                "    # Engagement with seasonality\n",
                "    is_viral = np.random.random() < 0.05\n",
                "    eng_rate = inf[\"engagement_rate\"] * SEASONALITY[month]\n",
                "    likes, comments, shares, saves = gen_engagement_metrics(inf[\"follower_count\"], eng_rate, is_viral)\n",
                "    \n",
                "    # Reach & impressions\n",
                "    reach = int(inf[\"follower_count\"] * np.random.uniform(0.20, 0.40))\n",
                "    impressions = int(reach * np.random.uniform(1.2, 1.8))\n",
                "    \n",
                "    posts.append({\n",
                "        \"post_id\": str(uuid4()),\n",
                "        \"influencer_id\": inf_id,\n",
                "        \"brand_id\": np.random.choice(brand_ids) if is_sponsored else None,\n",
                "        \"platform\": platform,\n",
                "        \"post_date\": post_date.strftime(\"%Y-%m-%d\"),\n",
                "        \"post_time_hour\": np.random.choice(range(6, 24), p=[0.02, 0.03, 0.05, 0.07, 0.08, 0.10, 0.12, 0.10, 0.07, 0.06, 0.05, 0.04, 0.06, 0.08, 0.10, 0.08, 0.05, 0.03]),\n",
                "        \"day_of_week\": np.random.choice(range(7), p=[0.12, 0.16, 0.17, 0.16, 0.14, 0.13, 0.12]),\n",
                "        \"content_type\": content_type,\n",
                "        \"caption_length\": int(np.clip(np.random.normal(180, 80), 20, 500)),\n",
                "        \"hashtag_count\": int(np.clip(np.random.normal(8 if platform == \"Instagram\" else 4, 3), 1, 30)),\n",
                "        \"has_cta\": np.random.random() < 0.45,\n",
                "        \"product_count\": np.random.poisson(2) if is_sponsored else 0,\n",
                "        \"visual_style\": sample_dist(VISUAL_STYLES)[0],\n",
                "        \"dominant_color\": np.random.choice(COLORS),\n",
                "        \"is_sponsored\": is_sponsored,\n",
                "        \"discount_code_present\": is_sponsored and np.random.random() < 0.30,\n",
                "        \"likes\": likes,\n",
                "        \"comments\": comments,\n",
                "        \"shares\": shares,\n",
                "        \"saves\": saves,\n",
                "        \"reach\": reach,\n",
                "        \"impressions\": impressions\n",
                "    })\n",
                "    \n",
                "    if (i + 1) % 10000 == 0:\n",
                "        print(f\"   ... {i+1:,} posts generated\")\n",
                "\n",
                "posts_df = pd.DataFrame(posts)\n",
                "print(f\"‚úÖ Generated {len(posts_df)} posts\")\n",
                "posts_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.4 Generate Conversions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üõí Generating Conversions...\")\n",
                "\n",
                "sponsored_posts = posts_df[posts_df[\"is_sponsored\"] == True].copy()\n",
                "brand_lookup = brands_df.set_index(\"brand_id\").to_dict(\"index\")\n",
                "product_categories = [\"Clothing\", \"Accessories\", \"Footwear\", \"Bags\", \"Jewelry\"]\n",
                "\n",
                "conversions = []\n",
                "for i in range(N_CONVERSIONS):\n",
                "    has_attribution = np.random.random() < 0.65\n",
                "    \n",
                "    if has_attribution and len(sponsored_posts) > 0:\n",
                "        post = sponsored_posts.sample(1).iloc[0]\n",
                "        post_id = post[\"post_id\"]\n",
                "        influencer_id = post[\"influencer_id\"]\n",
                "        brand_id = post[\"brand_id\"]\n",
                "        post_date = datetime.strptime(post[\"post_date\"], \"%Y-%m-%d\")\n",
                "        journey_length = int(np.clip(np.random.exponential(7), 1, 90))\n",
                "        conversion_date = min(post_date + timedelta(days=journey_length), end_date)\n",
                "    else:\n",
                "        post_id = None\n",
                "        influencer_id = None\n",
                "        brand_id = np.random.choice(brand_ids)\n",
                "        random_days = np.random.randint(0, date_range)\n",
                "        conversion_date = start_date + timedelta(days=random_days)\n",
                "        journey_length = int(np.clip(np.random.exponential(7), 1, 90))\n",
                "    \n",
                "    brand_tier = brand_lookup[brand_id][\"brand_tier\"] if brand_id else \"Mid-market\"\n",
                "    \n",
                "    conversions.append({\n",
                "        \"conversion_id\": str(uuid4()),\n",
                "        \"customer_id\": str(uuid4()),\n",
                "        \"post_id\": post_id,\n",
                "        \"influencer_id\": influencer_id,\n",
                "        \"brand_id\": brand_id,\n",
                "        \"conversion_date\": conversion_date.strftime(\"%Y-%m-%d\"),\n",
                "        \"attribution_type\": np.random.choice([\"first_touch\", \"last_touch\", \"linear\", \"time_decay\", \"position_based\"], p=[0.15, 0.25, 0.20, 0.25, 0.15]),\n",
                "        \"utm_source\": np.random.choice([\"instagram\", \"tiktok\", \"youtube\", \"twitter\", \"direct\", \"organic\"]),\n",
                "        \"utm_medium\": np.random.choice([\"social\", \"influencer\", \"organic\", \"paid\"]),\n",
                "        \"order_value\": gen_order_value(brand_tier),\n",
                "        \"product_category\": np.random.choice(product_categories),\n",
                "        \"discount_code_used\": post_id is not None and np.random.random() < 0.40,\n",
                "        \"customer_journey_length\": journey_length,\n",
                "        \"touchpoints_count\": int(np.clip(np.random.geometric(0.3), 1, 15))\n",
                "    })\n",
                "    \n",
                "    if (i + 1) % 10000 == 0:\n",
                "        print(f\"   ... {i+1:,} conversions generated\")\n",
                "\n",
                "conversions_df = pd.DataFrame(conversions)\n",
                "print(f\"‚úÖ Generated {len(conversions_df)} conversions\")\n",
                "conversions_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.5 Generate Touchpoints"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üîó Generating Touchpoints...\")\n",
                "\n",
                "conversions_with_posts = conversions_df[conversions_df[\"post_id\"].notna()].copy()\n",
                "touchpoint_types = [\"view\", \"click\", \"save\", \"like\", \"comment\", \"website_visit\", \"add_to_cart\"]\n",
                "post_ids = posts_df[\"post_id\"].tolist()\n",
                "\n",
                "touchpoints = []\n",
                "for i in range(N_TOUCHPOINTS):\n",
                "    leads_to_conversion = np.random.random() < 0.30\n",
                "    \n",
                "    if leads_to_conversion and len(conversions_with_posts) > 0:\n",
                "        conv = conversions_with_posts.sample(1).iloc[0]\n",
                "        conversion_id = conv[\"conversion_id\"]\n",
                "        customer_id = conv[\"customer_id\"]\n",
                "        post_id = conv[\"post_id\"]\n",
                "        conv_date = datetime.strptime(conv[\"conversion_date\"], \"%Y-%m-%d\")\n",
                "        days_before = np.random.randint(0, max(1, conv[\"customer_journey_length\"]))\n",
                "        touchpoint_date = conv_date - timedelta(days=days_before)\n",
                "    else:\n",
                "        conversion_id = None\n",
                "        customer_id = str(uuid4())\n",
                "        post_id = np.random.choice(post_ids) if np.random.random() < 0.7 else None\n",
                "        random_days = np.random.randint(0, date_range)\n",
                "        touchpoint_date = start_date + timedelta(days=random_days)\n",
                "    \n",
                "    platform = np.random.choice([\"Instagram\", \"TikTok\", \"YouTube\", \"Twitter\", \"Website\"])\n",
                "    \n",
                "    touchpoints.append({\n",
                "        \"touchpoint_id\": str(uuid4()),\n",
                "        \"customer_id\": customer_id,\n",
                "        \"post_id\": post_id,\n",
                "        \"touchpoint_type\": np.random.choice(touchpoint_types, p=[0.35, 0.20, 0.10, 0.15, 0.05, 0.10, 0.05]),\n",
                "        \"touchpoint_date\": touchpoint_date.strftime(\"%Y-%m-%d\"),\n",
                "        \"platform\": platform,\n",
                "        \"contributed_to_conversion\": leads_to_conversion,\n",
                "        \"conversion_id\": conversion_id,\n",
                "        \"attribution_weight\": round(np.random.uniform(0.05, 0.40), 3) if leads_to_conversion else 0.0\n",
                "    })\n",
                "    \n",
                "    if (i + 1) % 25000 == 0:\n",
                "        print(f\"   ... {i+1:,} touchpoints generated\")\n",
                "\n",
                "touchpoints_df = pd.DataFrame(touchpoints)\n",
                "print(f\"‚úÖ Generated {len(touchpoints_df)} touchpoints\")\n",
                "touchpoints_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Save Datasets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create data directory\n",
                "data_dir = Path(\"../data/raw\")\n",
                "data_dir.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# Save all datasets\n",
                "brands_df.to_csv(data_dir / \"brands.csv\", index=False)\n",
                "influencers_df.to_csv(data_dir / \"influencers.csv\", index=False)\n",
                "posts_df.to_csv(data_dir / \"posts.csv\", index=False)\n",
                "conversions_df.to_csv(data_dir / \"conversions.csv\", index=False)\n",
                "touchpoints_df.to_csv(data_dir / \"touchpoints.csv\", index=False)\n",
                "\n",
                "print(\"üíæ Datasets saved to ../data/raw/\")\n",
                "print(f\"\\nüìä Dataset Summary:\")\n",
                "print(f\"   - brands.csv: {len(brands_df):,} records\")\n",
                "print(f\"   - influencers.csv: {len(influencers_df):,} records\")\n",
                "print(f\"   - posts.csv: {len(posts_df):,} records\")\n",
                "print(f\"   - conversions.csv: {len(conversions_df):,} records\")\n",
                "print(f\"   - touchpoints.csv: {len(touchpoints_df):,} records\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Data Validation & Bias Checks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"‚öñÔ∏è BIAS ANALYSIS\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Gender distribution\n",
                "print(\"\\nüîπ Gender Distribution:\")\n",
                "gender_dist = influencers_df[\"gender\"].value_counts(normalize=True)\n",
                "for gender, pct in gender_dist.items():\n",
                "    expected = GENDER_DIST.get(gender, 0)\n",
                "    diff = abs(pct - expected)\n",
                "    status = \"‚úÖ\" if diff < 0.05 else \"‚ö†Ô∏è\"\n",
                "    print(f\"   {status} {gender}: {pct:.1%} (expected: {expected:.1%})\")\n",
                "\n",
                "# Geographic distribution\n",
                "print(\"\\nüîπ Geographic Distribution:\")\n",
                "country_dist = influencers_df[\"country\"].value_counts(normalize=True)\n",
                "us_share = country_dist.get(\"United States\", 0)\n",
                "status = \"‚úÖ\" if us_share < 0.35 else \"‚ö†Ô∏è\"\n",
                "print(f\"   {status} US representation: {us_share:.1%} (target: <35%)\")\n",
                "print(f\"   Top 5: {dict(country_dist.head(5))}\")\n",
                "\n",
                "# Tier distribution\n",
                "print(\"\\nüîπ Influencer Tier Distribution:\")\n",
                "tier_dist = influencers_df[\"tier\"].value_counts(normalize=True)\n",
                "for tier, pct in tier_dist.items():\n",
                "    expected = TIER_DIST.get(tier, 0)\n",
                "    diff = abs(pct - expected)\n",
                "    status = \"‚úÖ\" if diff < 0.05 else \"‚ö†Ô∏è\"\n",
                "    print(f\"   {status} {tier}: {pct:.1%} (expected: {expected:.1%})\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"\\nüîó CORRELATION VALIDATION\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "# Followers vs Engagement (should be NEGATIVE)\n",
                "corr = influencers_df[\"follower_count\"].corr(influencers_df[\"engagement_rate\"])\n",
                "status = \"‚úÖ\" if corr < 0 else \"‚ùå\"\n",
                "print(f\"\\n   {status} Followers ‚Üî Engagement: {corr:.3f} (expected: negative)\")\n",
                "\n",
                "# Followers vs Cost (should be POSITIVE)\n",
                "corr = influencers_df[\"follower_count\"].corr(influencers_df[\"avg_collaboration_cost\"])\n",
                "status = \"‚úÖ\" if corr > 0 else \"‚ùå\"\n",
                "print(f\"   {status} Followers ‚Üî Cost: {corr:.3f} (expected: positive)\")\n",
                "\n",
                "# Likes vs Comments (should be POSITIVE)\n",
                "corr = posts_df[\"likes\"].corr(posts_df[\"comments\"])\n",
                "status = \"‚úÖ\" if corr > 0.5 else \"‚ö†Ô∏è\"\n",
                "print(f\"   {status} Likes ‚Üî Comments: {corr:.3f} (expected: positive)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Quick Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
                "\n",
                "# 1. Influencer Tier Distribution\n",
                "tier_order = [\"nano\", \"micro\", \"mid\", \"macro\", \"mega\"]\n",
                "tier_counts = influencers_df[\"tier\"].value_counts().reindex(tier_order)\n",
                "axes[0, 0].bar(tier_counts.index, tier_counts.values, color=sns.color_palette(\"husl\", 5))\n",
                "axes[0, 0].set_title(\"Influencer Tier Distribution\", fontweight=\"bold\")\n",
                "axes[0, 0].set_ylabel(\"Count\")\n",
                "\n",
                "# 2. Engagement Rate by Tier\n",
                "sns.boxplot(data=influencers_df, x=\"tier\", y=\"engagement_rate\", order=tier_order, ax=axes[0, 1], palette=\"husl\")\n",
                "axes[0, 1].set_title(\"Engagement Rate by Tier\", fontweight=\"bold\")\n",
                "axes[0, 1].set_ylabel(\"Engagement Rate (%)\")\n",
                "\n",
                "# 3. Platform Distribution\n",
                "platform_counts = influencers_df[\"platform\"].value_counts()\n",
                "axes[0, 2].pie(platform_counts.values, labels=platform_counts.index, autopct=\"%1.1f%%\", colors=sns.color_palette(\"husl\", 4))\n",
                "axes[0, 2].set_title(\"Platform Distribution\", fontweight=\"bold\")\n",
                "\n",
                "# 4. Posts Over Time\n",
                "posts_df[\"post_month\"] = pd.to_datetime(posts_df[\"post_date\"]).dt.to_period(\"M\")\n",
                "monthly_posts = posts_df.groupby(\"post_month\").size()\n",
                "axes[1, 0].plot(monthly_posts.index.astype(str), monthly_posts.values, marker=\"o\", linewidth=2)\n",
                "axes[1, 0].set_title(\"Posts Over Time (Seasonality)\", fontweight=\"bold\")\n",
                "axes[1, 0].tick_params(axis=\"x\", rotation=45)\n",
                "axes[1, 0].set_ylabel(\"Number of Posts\")\n",
                "\n",
                "# 5. Conversion Order Values\n",
                "sns.histplot(conversions_df[\"order_value\"], bins=50, ax=axes[1, 1], color=\"coral\")\n",
                "axes[1, 1].set_title(\"Order Value Distribution\", fontweight=\"bold\")\n",
                "axes[1, 1].set_xlabel(\"Order Value (USD)\")\n",
                "\n",
                "# 6. Followers vs Engagement Scatterplot\n",
                "sample = influencers_df.sample(500)\n",
                "axes[1, 2].scatter(sample[\"follower_count\"], sample[\"engagement_rate\"], alpha=0.5, c=sample[\"tier\"].map({\"nano\": 0, \"micro\": 1, \"mid\": 2, \"macro\": 3, \"mega\": 4}))\n",
                "axes[1, 2].set_title(\"Followers vs Engagement (Inverse Correlation)\", fontweight=\"bold\")\n",
                "axes[1, 2].set_xlabel(\"Follower Count\")\n",
                "axes[1, 2].set_ylabel(\"Engagement Rate (%)\")\n",
                "axes[1, 2].set_xscale(\"log\")\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(\"../data/data_validation_charts.png\", dpi=150, bbox_inches=\"tight\")\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n‚úÖ Validation charts saved to ../data/data_validation_charts.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ‚úÖ Data Generation Complete!\n",
                "\n",
                "**Generated Datasets:**\n",
                "- `brands.csv` - 25 fashion brands\n",
                "- `influencers.csv` - 1,500 influencers\n",
                "- `posts.csv` - 50,000 social media posts\n",
                "- `conversions.csv` - 30,000 e-commerce conversions\n",
                "- `touchpoints.csv` - 100,000 customer journey touchpoints\n",
                "\n",
                "**Next Steps:**\n",
                "1. Run `02_eda.ipynb` for Exploratory Data Analysis\n",
                "2. Run `03_attribution_modeling.ipynb` for multi-touch attribution\n",
                "3. Run `04_influencer_scoring.ipynb` for influencer effectiveness model"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}